# Exploration - what makes RL work

## RL cannot be defined fully as just an algorithm for solving MDP
Self - evaluating agent

## Bandit - a projection of RL but still captures the nature of RL
So we first seek solutions for the dillema  in relatively easy setting
and then generalize it to the full MDP setting.

### naive approach

### UCB

### Thompson Sampling

### Information Gain

